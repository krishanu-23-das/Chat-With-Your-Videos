{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pytube\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install langchain\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install ffmpeg\n",
        "!pip install -q streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "aLhODZR356nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "print(whisper.__file__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klwr3g_K1gtY",
        "outputId": "01d2055e-37ef-44b8-a611-5995999b9146"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2ZaukEX2dpEdTGQatDve7dPpmGL_3u8Eur4MtR4aXCYparH96"
      ],
      "metadata": {
        "id": "97Y9pfupxwoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok"
      ],
      "metadata": {
        "id": "K7QweRKUxz5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ1KJJVH4Nbe",
        "outputId": "e44ffb5c-c2ef-4148-a72a-b934ee84e023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from pytube import YouTube\n",
        "import os\n",
        "import whisper\n",
        "from moviepy.editor import *\n",
        "import datetime as dt\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = 'XXXXXXXXXXXXXXXXXXXXXXXXXXX",
        "\n",
        "\n",
        "def load_video(url):\n",
        "    yt = YouTube(url)\n",
        "    #video_stream = yt.streams.filter(file_extension=\"mp4\")\n",
        "    target_dir = os.path.join('/content')\n",
        "\n",
        "    #yt.streams.first().download()(output_path=target_dir)\n",
        "    st.write('----DOWNLOADING VIDEO FILE----')\n",
        "    file_path = yt.streams.filter(only_audio=True, subtype='webm', abr='160kbps').first().download(output_path=target_dir)\n",
        "    return file_path\n",
        "\n",
        "\n",
        "\n",
        "def process_video(path):\n",
        "    file_dir = path\n",
        "    st.write('Transcribing Video with whisper base model')\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(file_dir)\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def process_text(result):\n",
        "    texts, start_time_list = [], []\n",
        "    for res in result['segments']:\n",
        "        start = res['start']\n",
        "        text = res['text']\n",
        "\n",
        "        start_time = dt.datetime.fromtimestamp(start)\n",
        "        start_time_formatted = start_time.strftime(\"%H:%M:%S\")\n",
        "\n",
        "        #creating list of texts and start_time\n",
        "        texts.append(''.join(text))\n",
        "        start_time_list.append(start_time_formatted)\n",
        "\n",
        "    texts_with_timestamps = dict(zip(texts, start_time_list))\n",
        "\n",
        "    formatted_texts = {\n",
        "        text: dt.datetime.strptime(str(timestamp), '%H:%M:%S')\n",
        "        for text, timestamp in texts_with_timestamps.items()\n",
        "    }\n",
        "\n",
        "    #grouping the sentences in the interval of 30 seconds, & stoding the texts and starting time\n",
        "    # in group_texts & time_list reps\n",
        "\n",
        "    grouped_texts = []\n",
        "    current_group = ''\n",
        "    time_list = [list(formatted_texts.values())[0]]\n",
        "    previous_time = None\n",
        "    time_difference = dt.timedelta(seconds=30)\n",
        "\n",
        "    # Group texts based on time difference\n",
        "    for text, timestamp in formatted_texts.items():\n",
        "\n",
        "        if previous_time is None or timestamp - previous_time <= time_difference:\n",
        "            current_group += text\n",
        "        else:\n",
        "            grouped_texts.append(current_group)\n",
        "            time_list.append(timestamp)\n",
        "            current_group = text\n",
        "        previous_time = time_list[-1]\n",
        "\n",
        "    # Append the last group of texts\n",
        "    if current_group:\n",
        "        grouped_texts.append(current_group)\n",
        "\n",
        "    return grouped_texts, time_list\n",
        "\n",
        "\n",
        "\n",
        "def get_vectorstore(grouped_texts, time_list):\n",
        "\n",
        "    text = grouped_texts\n",
        "    time_stamps = time_list\n",
        "\n",
        "    time_stamps = [{'source': str(t.time())} for t in time_stamps]\n",
        "    embeddings = HuggingFaceEmbeddings()\n",
        "    vectorestore = FAISS.from_texts(texts=text, embedding=embeddings, metadatas=time_stamps)\n",
        "    return vectorestore\n",
        "\n",
        "\n",
        "\n",
        "def get_conversation(vectorstore):\n",
        "    llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
        "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        memory=memory,\n",
        "        retriever=vectorstore.as_retriever()\n",
        "    )\n",
        "    return conversation_chain\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    favicon_url = 'https://th.bing.com/th/id/R.087b4dc55ac459f86e6d11d402095394?rik=SfrwQLE7z60OLg&pid=ImgRaw&r=0&sres=1&sresct=1'\n",
        "    st.set_page_config(page_title='Chat with YouTube videos', page_icon=favicon_url)\n",
        "    st.header('Chat with your videos :film_frames:')\n",
        "    user_question = st.text_input('Enter your query here')\n",
        "\n",
        "    if 'vectorstore' not in st.session_state:\n",
        "      st.session_state.vectorstore = None\n",
        "\n",
        "\n",
        "    if 'message' not in st.session_state:\n",
        "        st.session_state.message = []\n",
        "\n",
        "    for message in st.session_state.message:\n",
        "        with st.chat_message(message['role']):\n",
        "            st.markdown(message['content'])\n",
        "\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.subheader('Your Video file')\n",
        "        url = st.text_input('Enter your URL here and click on \"Process\"')\n",
        "        if st.button('Process'):\n",
        "            with st.spinner('Processing'):\n",
        "\n",
        "                st.video(url)\n",
        "\n",
        "                #load the video\n",
        "                path = load_video(url)\n",
        "\n",
        "                #convert audio to text file using whisper\n",
        "                result = process_video(path)\n",
        "                st.write(result)\n",
        "\n",
        "                #Embeed & transfer the converted text into vectorstore\n",
        "                grouped_texts, time_list = process_text(result)\n",
        "                st.session_state.vectorstore = get_vectorstore(grouped_texts, time_list)\n",
        "\n",
        "            st.write(\"NOW YOU CAN START CHATTING\")\n",
        "\n",
        "\n",
        "    if user_question:\n",
        "      chain = get_conversation(st.session_state.vectorstore)\n",
        "\n",
        "      with st.chat_message('user'):\n",
        "            st.markdown(user_question)\n",
        "      st.session_state.message.append({'role': \"user\", \"content\": user_question})\n",
        "\n",
        "      with st.chat_message('assistant'):\n",
        "                        chain_answer = chain({'question':user_question, \"chat_history\": []}, return_only_outputs=True)\n",
        "                        response = chain_answer['answer']\n",
        "                        st.markdown(response)\n",
        "\n",
        "      st.session_state.message.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "fquozAz9xOj2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pgrep streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7brQI7ExhBC",
        "outputId": "97072bcf-447d-4ddd-f32d-f4aff41c955b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "# Setup a tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "public_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzSgNDuvx9K1",
        "outputId": "c5ecdc93-e866-472a-e3ba-c93a4310a749"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://3cbb-35-194-72-18.ngrok-free.app\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zoddpwl-x-87"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
